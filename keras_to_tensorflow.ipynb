{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Copyright (c) 2017, by the Authors: Amir H. Abdi\n",
    "This software is freely available under the MIT Public License. \n",
    "Please see the License file in the root for details.\n",
    "\n",
    "The following code snippet will convert the keras model file,\n",
    "which is saved using model.save('kerasmodel_weight_file'),\n",
    "to the freezed .pb tensorflow weight file which holds both the \n",
    "network architecture and its associated weights.\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nInput arguments:\\n\\nnum_output: this value has nothing to do with the number of classes, batch_size, etc., \\nand it is mostly equal to 1. If the network is a **multi-stream network** \\n(forked network with multiple outputs), set the value to the number of outputs.\\n\\nquantize: if set to True, use the quantize feature of Tensorflow\\n(https://www.tensorflow.org/performance/quantization) [default: False]\\n\\nuse_theano: Thaeno and Tensorflow implement convolution in different ways.\\nWhen using Keras with Theano backend, the order is set to 'channels_first'.\\nThis feature is not fully tested, and doesn't work with quantizization [default: False]\\n\\ninput_fld: directory holding the keras weights file [default: .]\\n\\noutput_fld: destination directory to save the tensorflow files [default: .]\\n\\ninput_model_file: name of the input weight file [default: 'model.h5']\\n\\noutput_model_file: name of the output weight file [default: args.input_model_file + '.pb']\\n\\ngraph_def: if set to True, will write the graph definition as an ascii file [default: False]\\n\\noutput_graphdef_file: if graph_def is set to True, the file name of the \\ngraph definition [default: model.ascii]\\n\\noutput_node_prefix: the prefix to use for output nodes. [default: output_node]\\n\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Input arguments:\n",
    "\n",
    "num_output: this value has nothing to do with the number of classes, batch_size, etc., \n",
    "and it is mostly equal to 1. If the network is a **multi-stream network** \n",
    "(forked network with multiple outputs), set the value to the number of outputs.\n",
    "\n",
    "quantize: if set to True, use the quantize feature of Tensorflow\n",
    "(https://www.tensorflow.org/performance/quantization) [default: False]\n",
    "\n",
    "use_theano: Thaeno and Tensorflow implement convolution in different ways.\n",
    "When using Keras with Theano backend, the order is set to 'channels_first'.\n",
    "This feature is not fully tested, and doesn't work with quantizization [default: False]\n",
    "\n",
    "input_fld: directory holding the keras weights file [default: .]\n",
    "\n",
    "output_fld: destination directory to save the tensorflow files [default: .]\n",
    "\n",
    "input_model_file: name of the input weight file [default: 'model.h5']\n",
    "\n",
    "output_model_file: name of the output weight file [default: args.input_model_file + '.pb']\n",
    "\n",
    "graph_def: if set to True, will write the graph definition as an ascii file [default: False]\n",
    "\n",
    "output_graphdef_file: if graph_def is set to True, the file name of the \n",
    "graph definition [default: model.ascii]\n",
    "\n",
    "output_node_prefix: the prefix to use for output nodes. [default: output_node]\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse input arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [-input_fld INPUT_FLD]\n",
      "                             [-output_fld OUTPUT_FLD]\n",
      "                             [-input_model_file INPUT_MODEL_FILE]\n",
      "                             [-output_model_file OUTPUT_MODEL_FILE]\n",
      "                             [-output_graphdef_file OUTPUT_GRAPHDEF_FILE]\n",
      "                             [-num_outputs NUM_OUTPUTS] [-graph_def GRAPH_DEF]\n",
      "                             [-output_node_prefix OUTPUT_NODE_PREFIX]\n",
      "                             [-quantize QUANTIZE]\n",
      "                             [-theano_backend THEANO_BACKEND] [-f F]\n",
      "\n",
      "set input arguments\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "  -input_fld INPUT_FLD\n",
      "  -output_fld OUTPUT_FLD\n",
      "  -input_model_file INPUT_MODEL_FILE\n",
      "  -output_model_file OUTPUT_MODEL_FILE\n",
      "  -output_graphdef_file OUTPUT_GRAPHDEF_FILE\n",
      "  -num_outputs NUM_OUTPUTS\n",
      "  -graph_def GRAPH_DEF\n",
      "  -output_node_prefix OUTPUT_NODE_PREFIX\n",
      "  -quantize QUANTIZE\n",
      "  -theano_backend THEANO_BACKEND\n",
      "  -f F\n",
      "('input args: ', Namespace(f='/root/.local/share/jupyter/runtime/kernel-88ec8829-6ea5-4876-8055-091564d462e4.json', graph_def=False, input_fld='.', input_model_file='model.h5', num_outputs=1, output_fld='', output_graphdef_file='model.ascii', output_model_file='', output_node_prefix='output_node', quantize=False, theano_backend=False))\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser(description='set input arguments')\n",
    "parser.add_argument('-input_fld', action=\"store\", \n",
    "                    dest='input_fld', type=str, default='.')\n",
    "parser.add_argument('-output_fld', action=\"store\", \n",
    "                    dest='output_fld', type=str, default='')\n",
    "parser.add_argument('-input_model_file', action=\"store\", \n",
    "                    dest='input_model_file', type=str, default='model.h5')\n",
    "parser.add_argument('-output_model_file', action=\"store\", \n",
    "                    dest='output_model_file', type=str, default='')\n",
    "parser.add_argument('-output_graphdef_file', action=\"store\", \n",
    "                    dest='output_graphdef_file', type=str, default='model.ascii')\n",
    "parser.add_argument('-num_outputs', action=\"store\", \n",
    "                    dest='num_outputs', type=int, default=1)\n",
    "parser.add_argument('-graph_def', action=\"store\", \n",
    "                    dest='graph_def', type=bool, default=False)\n",
    "parser.add_argument('-output_node_prefix', action=\"store\", \n",
    "                    dest='output_node_prefix', type=str, default='output_node')\n",
    "parser.add_argument('-quantize', action=\"store\", \n",
    "                    dest='quantize', type=bool, default=False)\n",
    "parser.add_argument('-theano_backend', action=\"store\", \n",
    "                    dest='theano_backend', type=bool, default=False)\n",
    "parser.add_argument('-f')\n",
    "args = parser.parse_args()\n",
    "parser.print_help()\n",
    "print('input args: ', args)\n",
    "\n",
    "if args.theano_backend is True and args.quantize is True:\n",
    "    raise ValueError(\"Quantize feature does not work with theano backend.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "mkdir() got an unexpected keyword argument 'exist_ok'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-3bd092c3cc7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_model_file\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_model_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_model_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.pb'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_fld\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mweight_file_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_fld\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_model_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: mkdir() got an unexpected keyword argument 'exist_ok'"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from keras import backend as K\n",
    "\n",
    "output_fld =  args.input_fld if args.output_fld == '' else args.output_fld\n",
    "if args.output_model_file == '':\n",
    "    args.output_model_file = str(Path(args.input_model_file).name) + '.pb'\n",
    "Path(output_fld).mkdir(parents=True, exist_ok=True)    \n",
    "weight_file_path = str(Path(args.input_fld) / args.input_model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load keras model and rename output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('output nodes names are: ', ['output_node0'])\n"
     ]
    }
   ],
   "source": [
    "K.set_learning_phase(0)\n",
    "if args.theano_backend:\n",
    "    K.set_image_data_format('channels_first')\n",
    "else:\n",
    "    K.set_image_data_format('channels_last')\n",
    "\n",
    "try:\n",
    "    net_model = load_model('model_multi-Copy1.h5')\n",
    "except ValueError as err:\n",
    "    print('''Input file specified ({}) only holds the weights, and not the model defenition.\n",
    "    Save the model using mode.save(filename.h5) which will contain the network architecture\n",
    "    as well as its weights. \n",
    "    If the model is saved using model.save_weights(filename.h5), the model architecture is \n",
    "    expected to be saved separately in a json format and loaded prior to loading the weights.\n",
    "    Check the keras documentation for more details (https://keras.io/getting-started/faq/)'''\n",
    "          .format(weight_file_path))\n",
    "    raise err\n",
    "num_output = args.num_outputs\n",
    "pred = [None]*num_output\n",
    "pred_node_names = [None]*num_output\n",
    "for i in range(num_output):\n",
    "    pred_node_names[i] = args.output_node_prefix+str(i)\n",
    "    pred[i] = tf.identity(net_model.outputs[i], name=pred_node_names[i])\n",
    "print('output nodes names are: ', pred_node_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[optional] write graph definition in ascii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = K.get_session()\n",
    "\n",
    "if args.graph_def:\n",
    "    f = args.output_graphdef_file \n",
    "    tf.train.write_graph(sess.graph.as_graph_def(), output_fld, f, as_text=True)\n",
    "    print('saved the graph definition in ascii format at: ', str(Path(output_fld) / f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert variables to constants and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 236 variables.\n",
      "Converted 236 variables to const ops.\n",
      "('saved the freezed graph (ready for inference) at: ', 'model.h5.pb')\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.framework import graph_util\n",
    "from tensorflow.python.framework import graph_io\n",
    "from tensorflow.tools.graph_transforms import TransformGraph\n",
    "if args.quantize:\n",
    "    transforms = [\"quantize_weights\", \"quantize_nodes\"]\n",
    "    transformed_graph_def = TransformGraph(sess.graph.as_graph_def(), [], pred_node_names, transforms)\n",
    "    constant_graph = graph_util.convert_variables_to_constants(sess, transformed_graph_def, pred_node_names)\n",
    "else:\n",
    "    constant_graph = graph_util.convert_variables_to_constants(sess, sess.graph.as_graph_def(), pred_node_names)    \n",
    "graph_io.write_graph(constant_graph, output_fld, args.output_model_file, as_text=False)\n",
    "print('saved the freezed graph (ready for inference) at: ', str(Path(output_fld) / args.output_model_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"import/prediction/bias:0\", shape=(5,), dtype=float32)\n",
      "Tensor(\"import/output_node0:0\", shape=(?, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "model_file = \"model.h5.pb\"\n",
    "\n",
    "def load_graph(pbmodelFile):\n",
    "    with tf.gfile.GFile(pbmodelFile, \"rb\") as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "\n",
    "    with tf.Graph().as_default() as graph:\n",
    "        tf.import_graph_def(graph_def)\n",
    "\n",
    "    input_name = graph.get_operations()[0].name+':0'\n",
    "    output_name = graph.get_operations()[-1].name+':0'\n",
    "\n",
    "    return graph, input_name, output_name\n",
    "\n",
    "\n",
    "graph, inputName, outputName = load_graph(model_file)\n",
    "input_x = graph.get_tensor_by_name(inputName)\n",
    "output_y = graph.get_tensor_by_name(outputName)\n",
    "\n",
    "print(input_x)\n",
    "print(output_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
